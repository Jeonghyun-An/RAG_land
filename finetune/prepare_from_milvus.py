# finetune/prepare_from_milvus.py
import json
import asyncio
from pathlib import Path
from typing import List, Dict
import random
import os

# âš ï¸ ìš´ì˜ ì„œë²„ ì •ë³´ (í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬)
MILVUS_HOST = os.getenv("MILVUS_HOST", "milvus") 
MILVUS_PORT = os.getenv("MILVUS_PORT", "19530")
MILVUS_COLLECTION = os.getenv("MILVUS_COLLECTION", "rag_chunks_v2")

async def extract_from_milvus(target_count: int = 3000):
    """
    Milvusì—ì„œ ì²­í¬ ì¶”ì¶œ í›„ QA ìƒì„±
    """
    print(f"ğŸ”— Connecting to Milvus: {MILVUS_HOST}:{MILVUS_PORT}")
    
    try:
        from pymilvus import connections, Collection
        
        # Milvus ì—°ê²°
        connections.connect(
            alias="default",
            host=MILVUS_HOST,
            port=MILVUS_PORT
        )
        
        print(f"âœ… Connected to Milvus")
        
        # ì»¬ë ‰ì…˜ ë¡œë“œ
        collection = Collection(MILVUS_COLLECTION)
        collection.load()
        
        print(f"ğŸ“Š Collection: {MILVUS_COLLECTION}")
        print(f"ğŸ“ˆ Total entities: {collection.num_entities}")
        
        # ëª¨ë“  ì²­í¬ ê°€ì ¸ì˜¤ê¸°
        results = collection.query(
            expr="chunk_index >= 0",
            output_fields=["doc_id", "section", "chunk", "page"],
            limit=min(target_count, collection.num_entities)
        )
        
        print(f"âœ… Extracted {len(results)} chunks from Milvus")
        
        # QA í˜ì–´ ìƒì„±
        qa_pairs = []
        for i, chunk in enumerate(results):
            if i % 100 == 0:
                print(f"Processing... {i}/{len(results)}")
            
            qa_pairs.extend(generate_qa_from_chunk(chunk))
        
        print(f"âœ… Generated {len(qa_pairs)} QA pairs")
        
        connections.disconnect("default")
        return qa_pairs
        
    except Exception as e:
        print(f"âŒ Error connecting to Milvus: {e}")
        print(f"ğŸ“ Tip: Check MILVUS_HOST and MILVUS_PORT environment variables")
        return []

def generate_qa_from_chunk(chunk: Dict) -> List[Dict]:
    """
    ì²­í¬ì—ì„œ ë‹¤ì–‘í•œ QA í˜ì–´ ìƒì„±
    """
    text = chunk.get('chunk', '').strip()
    section = chunk.get('section', '').strip()
    doc_id = chunk.get('doc_id', '')
    page = chunk.get('page', 0)
    
    # ë„ˆë¬´ ì§§ì€ ì²­í¬ ìŠ¤í‚µ
    if len(text) < 50:
        return []
    
    qa_pairs = []
    
    # íŒ¨í„´ 1: ì„¹ì…˜ ê¸°ë°˜ ì¼ë°˜ ì§ˆë¬¸
    if section:
        qa_pairs.append({
            "instruction": f"{section}ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
            "input": "",
            "output": text[:600]  # ìµœëŒ€ 600ì
        })
        
        # ìƒì„¸ ì§ˆë¬¸
        qa_pairs.append({
            "instruction": f"{section}ì˜ ë‚´ìš©ì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "input": f"ë¬¸ì„œ ID: {doc_id}",
            "output": text[:500]
        })
    
    # íŒ¨í„´ 2: ì •ì˜/ì˜ë¯¸ ì§ˆë¬¸
    if any(keyword in text for keyword in ["ì •ì˜", "ì˜ë¯¸", "ì´ë€", "refers to", "means"]):
        keyword = section if section else "ì´ ê°œë…"
        qa_pairs.append({
            "instruction": f"{keyword}ì˜ ì •ì˜ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
            "input": "",
            "output": text[:400]
        })
    
    # íŒ¨í„´ 3: ì ˆì°¨/ë°©ë²• ì§ˆë¬¸
    if any(keyword in text for keyword in ["ë°©ë²•", "ì ˆì°¨", "ë‹¨ê³„", "ê³¼ì •", "procedure", "method", "steps"]):
        keyword = section if section else "ì´ ì‘ì—…"
        qa_pairs.append({
            "instruction": f"{keyword}ì˜ ì ˆì°¨ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
            "input": "",
            "output": text[:500]
        })
    
    # íŒ¨í„´ 4: ê¸°ì¤€/ê·œì • ì§ˆë¬¸
    if any(keyword in text for keyword in ["ê¸°ì¤€", "í•œë„", "ì œí•œ", "ê·œì •", "ìš”êµ¬ì‚¬í•­", "criteria", "limit", "requirement"]):
        keyword = section if section else "ì´ í•­ëª©"
        qa_pairs.append({
            "instruction": f"{keyword}ì˜ ê¸°ì¤€ì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "input": "",
            "output": text[:450]
        })
    
    # íŒ¨í„´ 5: êµ¬ì„±ìš”ì†Œ ì§ˆë¬¸
    if any(keyword in text for keyword in ["êµ¬ì„±", "í¬í•¨", "ìš”ì†Œ", "ë¶€í’ˆ", "component", "consists of"]):
        keyword = section if section else "ì´ ì‹œìŠ¤í…œ"
        qa_pairs.append({
            "instruction": f"{keyword}ì˜ êµ¬ì„±ìš”ì†ŒëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
            "input": "",
            "output": text[:500]
        })
    
    # íŒ¨í„´ 6: ë²• ì¡°í•­ ì§ˆë¬¸ (í•œêµ­ì–´)
    if "ì œ" in text and "ì¡°" in text:
        qa_pairs.append({
            "instruction": f"ê´€ë ¨ ë²• ì¡°í•­ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
            "input": section,
            "output": text[:550]
        })
    
    # íŒ¨í„´ 7: IAEA ê´€ë ¨ ì§ˆë¬¸ (ì˜ë¬¸)
    if "IAEA" in text or "Safety Standards" in text:
        qa_pairs.append({
            "instruction": "IAEA ì•ˆì „ ê¸°ì¤€ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
            "input": section,
            "output": text[:500]
        })
    
    return qa_pairs

def save_dataset(data: List[Dict], output_path: str):
    """JSONL í˜•ì‹ìœ¼ë¡œ ì €ì¥"""
    output_file = Path(output_path)
    output_file.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_file, 'w', encoding='utf-8') as f:
        for item in data:
            f.write(json.dumps(item, ensure_ascii=False) + '\n')
    
    print(f"âœ… Saved {len(data)} examples to {output_path}")

async def main():
    print("="*60)
    print("ğŸ“Š Extracting QA Data from Milvus")
    print("="*60)
    
    # Milvusì—ì„œ ì¶”ì¶œ (ëª©í‘œ: 3000ê°œ ì²­í¬)
    qa_pairs = await extract_from_milvus(target_count=3000)
    
    if not qa_pairs:
        print("âŒ No data extracted. Check Milvus connection.")
        return
    
    print(f"\nğŸ“Š Generated {len(qa_pairs)} QA pairs")
    
    # ì¤‘ë³µ ì œê±°
    unique_qa = {}
    for qa in qa_pairs:
        key = f"{qa['instruction']}:{qa['output'][:100]}"
        if key not in unique_qa:
            unique_qa[key] = qa
    
    qa_pairs = list(unique_qa.values())
    print(f"âœ… After deduplication: {len(qa_pairs)} unique QA pairs")
    
    # Train/Test ë¶„í•  (90/10)
    random.shuffle(qa_pairs)
    split_idx = int(len(qa_pairs) * 0.9)
    
    train_data = qa_pairs[:split_idx]
    test_data = qa_pairs[split_idx:]
    
    # ì €ì¥
    save_dataset(train_data, "/workspace/data/nuclear_qa.jsonl")
    save_dataset(test_data, "/workspace/data/test_qa.jsonl")
    
    print("="*60)
    print(f"ğŸ“Š Final Dataset Statistics")
    print(f"   Train: {len(train_data)} examples")
    print(f"   Test:  {len(test_data)} examples")
    print(f"ğŸ’¾ Files saved to: /workspace/data/")
    print("="*60)
    
    # ìƒ˜í”Œ ì¶œë ¥
    print("\nğŸ“ Sample QA Pairs:\n")
    for i, qa in enumerate(train_data[:3]):
        print(f"--- Example {i+1} ---")
        print(f"Q: {qa['instruction']}")
        print(f"A: {qa['output'][:100]}...")
        print()

if __name__ == "__main__":
    asyncio.run(main())