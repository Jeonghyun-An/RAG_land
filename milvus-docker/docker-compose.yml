services:
  etcd:
    image: quay.io/coreos/etcd:v3.5.0
    container_name: etcd
    environment:
      - ETCD_AUTO_COMPACTION_RETENTION=1
      - ETCD_QUOTA_BACKEND_BYTES=4294967296
      - ETCD_SNAPSHOT_COUNT=50000
      - ETCD_ENABLE_V2=true
      - ETCD_LOG_LEVEL=info
      - ETCD_LISTEN_CLIENT_URLS=http://0.0.0.0:2379
      - ETCD_ADVERTISE_CLIENT_URLS=http://etcd:2379
      - ETCD_LISTEN_PEER_URLS=http://0.0.0.0:2380
      - ETCD_INITIAL_ADVERTISE_PEER_URLS=http://etcd:2380
      - ETCD_INITIAL_CLUSTER=default=http://etcd:2380
      - ETCD_NAME=default
      - ETCDCTL_API=3
    ports:
      - "2379:2379"
      - "2380:2380"
    volumes:
      - milvus_etcd_data:/etcd
    networks: [ragnet]
    healthcheck:
      # wget 대신 etcdctl로 헬스체크
      test:
        [
          "CMD",
          "etcdctl",
          "endpoint",
          "health",
          "--endpoints=http://127.0.0.1:2379",
        ]
      interval: 5s
      timeout: 3s
      retries: 10
    restart: unless-stopped
  gotenberg:
    image: gotenberg/gotenberg:8
    container_name: gotenberg
    networks: [ragnet]
    ports: [] # 외부 노출 불필요 (fastapi가 내부에서 호출)
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:3000/health"]
      interval: 5s
      timeout: 3s
      retries: 20
      start_period: 10s
    restart: unless-stopped

  minio:
    image: minio/minio:RELEASE.2023-01-20T02-05-44Z
    container_name: minio
    command: server /data --console-address ":9001"
    environment:
      MINIO_ACCESS_KEY: minioadmin
      MINIO_SECRET_KEY: minioadmin
      # 최신 이미지로 바꾸면:
      # MINIO_ROOT_USER: minioadmin
      # MINIO_ROOT_PASSWORD: minioadmin
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio_data:/data
    networks: [ragnet]
    healthcheck:
      # 이 이미지에 curl 있음(이미 Healthy 떴던 걸로 확인)
      test: ["CMD", "curl", "-fsS", "http://localhost:9000/minio/health/live"]
      interval: 5s
      timeout: 3s
      retries: 20
    restart: unless-stopped

  milvus:
    image: milvusdb/milvus:v2.2.11
    container_name: milvus
    command: ["milvus", "run", "standalone"]
    environment:
      - ETCD_ENDPOINTS=etcd:2379
      - MINIO_ADDRESS=minio:9000
      - MINIO_ACCESS_KEY=minioadmin
      - MINIO_SECRET_KEY=minioadmin
      - MINIO_USE_SSL=false
      # 버킷 이름(없으면 Milvus가 만들어줍니다)
      - MINIO_BUCKET_NAME=milvus-bucket
      # 일부 버전에서는 이 키를 씁니다(겸사겸사 넣어도 무해)
      - MINIO_BUCKET=milvus-bucket
    ports:
      - "19530:19530"
      - "9091:9091"
    volumes:
      - milvus_data:/var/lib/milvus
    networks:
      - ragnet
    depends_on:
      etcd:
        condition: service_healthy
      minio:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-fsS", "http://localhost:9091/healthz"]
      interval: 5s
      timeout: 3s
      retries: 20
    restart: unless-stopped

  vllm-a4000:
    image: vllm/vllm-openai:latest
    container_name: vllm-a4000
    gpus: all
    networks: [ragnet]
    ports:
      - "8001:8000"
    environment:
      # 허깅페이스 토큰(게이팅 모델 쓸 때 필요)
      HUGGINGFACE_HUB_TOKEN: "${HUGGINGFACE_TOKEN}"
      HF_TOKEN: "${HUGGINGFACE_TOKEN}"
      HF_HOME: "/models"
      # FlashInfer가 카드/드라이버와 안 맞아 커널 에러가 나면 아래 한 줄만 '0'으로 바꿔 한 번 시도
      TRANSFORMERS_OFFLINE: "0"
      VLLM_USE_FLASHINFER: "0"
    volumes:
      - ../models/.hf-cache:/models:rw
    command: [
        "--model",
        "meta-llama/Llama-3.2-3B-Instruct", # 3B Instruct 권장(16GB에서 안정/속도 모두 무난)
        "--served-model-name",
        "llama-3.2-3b",
        "--download-dir",
        "/models", # 캐시 공유
        "--max-model-len",
        "4096", # 너무 크게 잡으면 KV가 VRAM 잡아먹음
        "--dtype",
        "float16", # A4000은 fp16이 안전
        "--gpu-memory-utilization",
        "0.90", # 여유 있게 85%
        "--max-num-seqs",
        "12", # 동시 배치. 단일요청 위주면 8~16 적당
      ]
    healthcheck:
      test: ["CMD", "curl", "-fsS", "http://localhost:8000/v1/models"]
      interval: 10s
      timeout: 5s
      retries: 30
    restart: unless-stopped

  fastapi:
    build:
      context: ..
      dockerfile: milvus-docker/Dockerfile
      # args:
      # INSTALL_TESSERACT: "0" # 1로 하면 tesseract-ocr-kor 포함 설치
    container_name: fastapi
    ports:
      - "8000:8000"
    volumes:
      - ..:/app
      - ../models/.hf-cache:/models
    gpus: all
    environment:
      IS_DOCKER: "true"
      # MinIO/Milvus 접속 명시 (컨테이너 네트워크 이름으로)
      MINIO_ENDPOINT: "minio:9000"
      MINIO_ACCESS_KEY: "minioadmin"
      MINIO_SECRET_KEY: "minioadmin"
      MILVUS_HOST: "milvus"
      MILVUS_PORT: "19530"
      MILVUS_COLLECTION: "rag_chunks_m3_v2"
      RAG_JOB_STATE_PERSIST: "minio"
      MILVUS_SECTION_MAX: "512" # 섹션 최대 문자 수
      MILVUS_DOCID_MAX: "256" # doc_id 최대 문자 수
      MILVUS_CHUNK_MAX: "8192" # 청크 최대 문자 수
      RAG_SECTION_MAX: "200" # 레이아웃 인지 청킹 섹션 최대 문자 수
      SEC_CAP: "160" # 레이아웃 인지 청킹 섹션 최대 문자 수
      # 벡터 검색 파라미터
      MILVUS_INDEX_TYPE: "HNSW"
      MILVUS_METRIC_TYPE: "IP" # IP=cosine, L2=L2, HAMMING=해밍, JACCARD=자카드
      MILVUS_HNSW_M: "16"
      MILVUS_HNSW_EFCON: "200"
      MILVUS_EF_SEARCH: 384
      MILVUS_EF_PER_K: "8"
      MILVUS_EF_MAX: "2048"
      # 검색/하이브리드/리랭크
      RAG_TOPK_INIT: "80" # 초기 후보폭 (top_k와 별개)
      RAG_HYBRID_ALPHA: "0.7" # 0~1 (벡터 가중)
      RAG_USE_HYBRID: 1
      RAG_HYBRID_WEIGHT_VEC: "0.8" # 벡터:키워드 = 0.8:0.2
      MILVUS_SEARCH_EF: 256 # topk가 커지면 더 키워도 됨 (512 등)
      RAG_SCORE_THRESHOLD: 0.25 # 리랭커 스코어 컷오프
      RAG_CONTEXT_BUDGET_TOKENS: "1024" # 최대 컨텍스트 토큰 수
      # 컬렉션 초기화/업서트 옵션 (필요 시만 1로)
      RAG_RESET_COLLECTION: "0"
      # Dedup / 교체 정책
      RAG_SKIP_IF_EXISTS: "0" # 같은 doc_id 있으면 스킵 (매니페스트 OFF일 때)
      RAG_REPLACE_DOC: "1" # 같은 doc_id 있으면 삭제 후 재삽입
      RAG_DEDUP_MANIFEST: "1" # MinIO docs/{doc_id}.json 해시 비교/저장
      RAG_UNIQUE_SUFFIX_ON_CONFLICT: "1" # REPLACE=0이고 충돌이면 doc_id__hash 로 새로 삽입
      RAG_DELETE_AFTER_INDEX: "0"
      RAG_NO_LOCAL: "1"
      RAG_SKIP_IF_UPLOADED: "1" # MinIO에 이미 업로드된 파일이면 스킵
      RAG_REPLACE_BEFORE_INSERT: "0" # 업로드 전에 doc_id 중복 검사 후 교체
      RAG_RETRY_AFTER_DELETE: "1" # 삭제 후 재삽입 시도
      DOC_CONVERTER_URL:
      # RAG 청킹/인코딩 옵션
      RAG_CHUNK_TOKENS: 320 # 청킹 토큰 수(256 최적, 지금은 임베딩 모델이 로컬용이라 구려서 낮춤)
      RAG_CHUNK_OVERLAP: 64 # 청킹 오버랩 토큰 수(64 최적)
      RAG_MIN_CHUNK_TOKENS: 64 # 너무 작은 청크는 병합

      RAG_PARSE_LAYOUT: 1 # 레이아웃 인지 청킹
      RAG_PARSE_LAYOUT_MIN_CHARS: 100 # 레이아웃 인지 청킹 최소 문자 수
      RAG_PARSE_LAYOUT_MAX_TOKENS: 512 # 레이아웃 인지 청킹 최대 토큰 수
      RAG_PARSE_LAYOUT_MIN_WORDS: 8 # 레이아웃 인지 청킹 최소 단어 수
      RAG_PARSE_LAYOUT_MAX_WORDS: 100 # 레이아웃 인지 청킹 최대 단어 수
      RAG_CROSS_PAGE_CHUNK: "0" # 페이지 경계 넘는 청킹 허용
      RAG_STRIP_REPEAT_MINRATIO: "0.2" # 반복 라인 비율 컷오프 (0이면 끔)
      RAG_FIX_TAIL_HEADING: "1" # 제목이 꼬리에만 있는 경우 다음 청크로 이관
      RAG_IGNORE_RUNNING_HEADER: "1" # 러닝헤더/푸터 제거
      RAG_PACK_BY_ARTICLE: "0" # 조문 단위로 묶고 싶을 때만 1
      RAG_ARTICLE_TARGET_TOKENS: "800"
      # --- RAG 청킹/인코딩 옵션 ---
      RAG_PARSE_PDF: "1" # PDF 파싱 여부
      RAG_PARSE_DOCX: "1" # DOCX 파싱 여부
      RAG_PARSE_XLSX: "1" # XLSX 파싱 여부
      RAG_PARSE_TXT: "1" # TXT 파싱 여부
      RAG_PARSE_HTML: "1" # HTML 파싱 여부
      RAG_PARSE_PPTX: "1" # PPTX 파싱 여부
      # --- DEBUG/로깅 ---
      DEBUG_PEEK_MAX_CHARS: 0 # 디버그용: 청크 미리보기 최대 문자 수
      # --- OCR/파서 ---
      OCR_MODE: "force" # auto | always | never
      OCR_ENGINE: "easyocr" # paddle | tesseract | easyocr
      OCR_LANG: "ko,en" # paddle: korean / tesseract: kor+eng / easyocr: ko,en
      OCR_LANGS: "kor+eng"
      OCR_DPI: "300"
      OCR_MIN_CHARS: "40"
      OCR_MIN_CHARS_PER_PAGE: "50"
      OCR_MAX_PAGES_FOR_OCR: "800"
      # tesseract 바이너리 경로가 필요하면(윈도우 베이스 아님) 비워둬도 OK
      OCR_TESSERACT_CMD: ""
      OCR_EASYOCR_GPU: "1"

      # --- 변환(pdf_converter) ---
      GOTENBERG_URL: "http://gotenberg:3000"
      CONVERT_BACKENDS: "gotenberg,soffice" # gotenberg 실패 시 soffice 폴백
      GOTENBERG_TIMEOUT: "120"
      GOTENBERG_MAX_RETRIES: "3"
      GOTENBERG_BACKOFF_BASE: "0.6"
      PDF_PAPER: "A4" # 보고서 품질 안정용
      PDF_MARGIN_MM: "10"

      # --- DOCX/XLSX direct 파싱 여부 ---
      RAG_PARSE_DIRECT_DOCX: "1"
      RAG_PARSE_DIRECT_XLSX: "1"
      RAG_CONVERT_NONPDF_TO_PDF: "1" # 기타 포맷 변환 허용
      # 임베딩
      EMBEDDING_MODEL: "BAAI/bge-m3"
      EMBEDDING_DEVICE: "cuda" # cpu 또는 cuda
      EMBED_MAX_TOKENS: "512"
      EMBED_BATCH_SIZE: "128"
      EMBED_NUM_THREADS: "2"
      TOKENIZER_PARALLELISM: "false" # 토크나이저 병렬화 (true/false)
      EMBED_DTYPE: "auto" # auto, float16, float32
      HF_TOKENIZER_NAME: "BAAI/bge-m3"
      # reranker
      RERANKER_MODEL: "BAAI/bge-reranker-v2-m3"
      RERANKER_DEVICE: "cuda" # cpu 또는 cuda
      RERANKER_BACKENDS: "ce,flag"
      RERANKER_BATCH_SIZE: "64"
      CE_FALLBACK_MODEL: "cross-encoder/ms-marco-MiniLM-L-6-v2"

      # 모델 기본값/토큰
      MODEL_ID: "meta-llama/Llama-3.2-3B-Instruct"
      HUGGINGFACE_TOKEN: "${HUGGINGFACE_TOKEN}" # .env나 OS env에서 가져옴(없으면 빈 값)
      PYTHONUNBUFFERED: "1"
      OPENAI_BASE_URL: "http://vllm-a4000:8000/v1"
      OPENAI_API_KEY: "not-used"
      MODEL_ALIASES: >
        {"llama-3.2-3b":"meta-llama/Llama-3.2-3B-Instruct",
         "llama-3.2-1b":"meta-llama/Llama-3.2-1B-Instruct"}
      USE_VLLM: "1" # vllm 프로필을 켜면 1로 바꾸기
      HF_HOME: "/models"
      OPENAI_ALIAS_URLS: >
        {"llama-3.2-3b":"http://vllm-a4000:8000/v1"}
      # (선택) vllm 프로필을 켜면 아래 ENV도 설정
      # (선택) 기본 별칭명도 ENV로
      DEFAULT_MODEL_ALIAS: "llama-3.2-3b"
    networks:
      - ragnet
    depends_on:
      milvus:
        condition: service_healthy
      minio:
        condition: service_healthy
      gotenberg:
        condition: service_healthy
      vllm-a4000:
        condition: service_healthy
    restart: unless-stopped

volumes:
  milvus_etcd_data:
  milvus_data:
  minio_data:

networks:
  ragnet:
