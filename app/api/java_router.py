# app/api/java_router.py
"""
Java ì‹œìŠ¤í…œ ì—°ë™ ë¼ìš°í„° (ìš´ì˜ìš©)
- ì„œë²„ íŒŒì¼ì‹œìŠ¤í…œ ì‚¬ìš©
- DB ì™„ì „ ì—°ë™
- ì‹¤ì œ ìš´ì˜ í™˜ê²½ ì „ìš©
"""
from __future__ import annotations

import os
import hashlib
import hmac
import uuid
from datetime import datetime
from typing import Optional, Dict, Any
from pathlib import Path

from fastapi import APIRouter, HTTPException, Header, BackgroundTasks
from pydantic import BaseModel
import httpx

from app.services.db_connector import DBConnector
from app.services.pdf_converter import convert_to_pdf, ConvertError
from app.services import job_state

router = APIRouter(prefix="/java", tags=["java-production"])

# í™˜ê²½ë³€ìˆ˜
SHARED_SECRET = os.getenv("JAVA_SHARED_SECRET", "")
SERVER_BASE_PATH = os.getenv("SERVER_BASE_PATH", "/mnt/shared")


# ==================== Schemas ====================
class ConvertAndIndexRequest(BaseModel):
    """ìë°” â†’ AI íŠ¸ë¦¬ê±° ìš”ì²­"""
    data_id: str
    path: str  # ì„œë²„ íŒŒì¼ì‹œìŠ¤í…œ ìƒëŒ€ ê²½ë¡œ
    file_id: str
    webhook_url: Optional[str] = None
    ocr_manual_required: bool = False
    reindex_required_yn: bool = False


class ConvertAndIndexResponse(BaseModel):
    """ì¦‰ì‹œ ì‘ë‹µ"""
    status: str
    job_id: str
    data_id: str
    message: str


class WebhookPayload(BaseModel):
    """AI â†’ ìë°” ì½œë°± í˜ì´ë¡œë“œ"""
    job_id: str
    data_id: str
    status: str
    converted: bool = False
    metrics: Optional[Dict[str, Any]] = None
    timestamps: Optional[Dict[str, str]] = None
    message: str = ""
    chunk_count: Optional[int] = None


class StatusResponse(BaseModel):
    """ìƒíƒœ ì¡°íšŒ ì‘ë‹µ"""
    data_id: str
    rag_index_status: str
    parse_yn: Optional[str] = None
    chunk_count: Optional[int] = None
    parse_start_dt: Optional[str] = None
    parse_end_dt: Optional[str] = None
    milvus_doc_id: Optional[str] = None


# ==================== Helper Functions ====================
def verify_internal_token(token: Optional[str]) -> bool:
    if not token:
        return False
    return token == SHARED_SECRET


def generate_hmac_signature(payload: str, secret: str) -> str:
    return hmac.new(
        secret.encode('utf-8'),
        payload.encode('utf-8'),
        hashlib.sha256
    ).hexdigest()


async def send_webhook(url: str, payload: WebhookPayload, secret: str):
    try:
        payload_json = payload.model_dump_json()
        signature = generate_hmac_signature(payload_json, secret)
        
        headers = {
            'Content-Type': 'application/json',
            'X-Webhook-Signature': signature
        }
        
        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.post(url, content=payload_json, headers=headers)
            response.raise_for_status()
            print(f"[PROD-WEBHOOK] âœ… Sent to {url}")
    except Exception as e:
        print(f"[PROD-WEBHOOK] âŒ Failed: {e}")


# ==================== Background Task ====================
async def process_convert_and_index_prod(
    job_id: str,
    data_id: str,
    path: str,
    file_id: str,
    webhook_url: Optional[str],
    ocr_manual_required: bool,
    reindex_required_yn: bool
):
    """
    ìš´ì˜ìš© ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬
    - llama_routerì˜ index_pdf_to_milvus() ì¬ì‚¬ìš©
    - DB ì™„ì „ ì—…ë°ì´íŠ¸
    """
    db = DBConnector()
    start_time = datetime.utcnow()
    
    job_state.start(job_id, data_id, file_id)
    db.mark_ocr_start(data_id)
    
    try:
        # ========== Step 1: ì„œë²„ íŒŒì¼ ë¡œë“œ ==========
        job_state.update(job_id, status="uploaded", step="Loading file from server")
        
        full_path = os.path.join(SERVER_BASE_PATH, path, file_id)
        
        if not os.path.exists(full_path):
            raise FileNotFoundError(f"ì„œë²„ íŒŒì¼ ì—†ìŒ: {full_path}")
        
        print(f"[PROD] Using server file: {full_path}")
        
        # ========== Step 2: PDF ë³€í™˜ (í•„ìš”ì‹œ) ==========
        job_state.update(job_id, status="parsing", step="Converting to PDF if needed")
        
        is_already_pdf = file_id.lower().endswith('.pdf')
        converted_pdf_path = full_path
        
        if not is_already_pdf:
            try:
                # PDF ë³€í™˜
                converted_pdf_path = convert_to_pdf(full_path)
                converted_name = os.path.splitext(file_id)[0] + '.pdf'
                
                # ì„œë²„ íŒŒì¼ì‹œìŠ¤í…œì— ì €ì¥
                final_pdf_path = os.path.join(SERVER_BASE_PATH, path, converted_name)
                
                # ë³€í™˜ëœ íŒŒì¼ ë³µì‚¬ (convert_to_pdfê°€ ì„ì‹œ ê²½ë¡œì— ìƒì„±í–ˆì„ ê²½ìš°)
                if converted_pdf_path != final_pdf_path:
                    import shutil
                    shutil.copy2(converted_pdf_path, final_pdf_path)
                    converted_pdf_path = final_pdf_path
                
                # DB ì—…ë°ì´íŠ¸: ë³€í™˜ëœ íŒŒì¼ ê²½ë¡œ
                folder_only = path
                prefix = "COMMON/oskData/"
                if folder_only.startswith(prefix):
                    folder_only = folder_only[len(prefix):]
                db.update_converted_file_path(data_id, folder_only, converted_name)
                
                print(f"[PROD] âœ… PDF converted and saved: {converted_pdf_path}")
                    
            except ConvertError as ce:
                raise RuntimeError(f"PDF ë³€í™˜ ì‹¤íŒ¨: {ce}")
            except Exception as e:
                print(f"[PROD] âŒ Conversion error: {e}")
                raise RuntimeError(f"PDF ë³€í™˜/ì €ì¥ ì‹¤íŒ¨: {e}")
        
        # PDF ë³€í™˜ ì™„ë£Œ ì›¹í›…
        if webhook_url:
            await send_webhook(
                webhook_url,
                WebhookPayload(
                    job_id=job_id,
                    data_id=data_id,
                    status="pdf_converted",
                    converted=not is_already_pdf,
                    metrics={"converted": not is_already_pdf},
                    timestamps={"start": start_time.isoformat()}
                ),
                SHARED_SECRET
            )
        
        # ========== Step 3: ê³ ë„í™”ëœ ì²­í‚¹ & ì¸ë±ì‹± (llama_router ì¬ì‚¬ìš©) ==========
        job_state.update(job_id, status="processing", step="Using advanced indexing pipeline")
        
        # ğŸ”¥ í•µì‹¬: OCR ëª¨ë“œë¥¼ 'never'ë¡œ ì„¤ì • (ë³€í™˜ëœ PDFëŠ” í…ìŠ¤íŠ¸ í¬í•¨)
        original_ocr_mode = os.environ.get("OCR_MODE")
        try:
            if not is_already_pdf:
                os.environ["OCR_MODE"] = "never"  # ë³€í™˜ëœ PDFëŠ” OCR ë¶ˆí•„ìš”
            
            # llama_routerì˜ ê³ ë„í™”ëœ ì¸ë±ì‹± íŒŒì´í”„ë¼ì¸ í˜¸ì¶œ
            from app.api.llama_router import index_pdf_to_milvus
            
            index_pdf_to_milvus(
                job_id=job_id,
                file_path=converted_pdf_path,
                minio_object=None,  # ìš´ì˜ì—ì„œëŠ” ë¡œì»¬ íŒŒì¼ ìš°ì„ 
                uploaded=True,
                remove_local=False,  # ì„œë²„ íŒŒì¼ì€ ìœ ì§€
                doc_id=data_id
            )
            
        finally:
            # í™˜ê²½ë³€ìˆ˜ ë³µì›
            if original_ocr_mode is not None:
                os.environ["OCR_MODE"] = original_ocr_mode
            elif "OCR_MODE" in os.environ:
                del os.environ["OCR_MODE"]
        
        # ========== Step 4: ê²°ê³¼ ì¡°íšŒ ë° DB ì—…ë°ì´íŠ¸ ==========
        state = job_state.get(job_id) or {}
        chunks = state.get('chunks', 0)
        pages = state.get('pages', 0)
        
        print(f"[PROD] âœ… Indexing completed: {pages} pages, {chunks} chunks")
        
        # DB ì—…ë°ì´íŠ¸: RAG ì¸ë±ì‹± ì™„ë£Œ
        db.update_rag_completed(
            data_id,
            chunks=chunks,
            doc_id=data_id
        )
        
        # ========== Step 5: ì™„ë£Œ & Webhook ==========
        end_time = datetime.utcnow()
        
        if webhook_url:
            payload = WebhookPayload(
                job_id=job_id,
                data_id=data_id,
                status="done",
                converted=not is_already_pdf,
                metrics={"pages": pages, "chunks": chunks},
                chunk_count=chunks,
                timestamps={
                    "start": start_time.isoformat(), 
                    "end": end_time.isoformat()
                },
                message="converted and indexed" if not is_already_pdf else "indexed"
            )
            await send_webhook(webhook_url, payload, SHARED_SECRET)
    
    except Exception as e:
        job_state.fail(job_id, str(e))
        db.update_parse_status(data_id, rag_status="error")
        print(f"[PROD] âŒ Error: {e}")
        
        if webhook_url:
            payload = WebhookPayload(
                job_id=job_id,
                data_id=data_id,
                status="error",
                message=str(e)
            )
            await send_webhook(webhook_url, payload, SHARED_SECRET)
        
        raise


# ==================== Routes ====================
@router.post("/convert-and-index", response_model=ConvertAndIndexResponse)
async def convert_and_index(
    request: ConvertAndIndexRequest,
    background_tasks: BackgroundTasks,
    x_internal_token: Optional[str] = Header(None)
):
    """
    ìë°” â†’ AI íŠ¸ë¦¬ê±° API (ìš´ì˜ìš©)
    """
    if not verify_internal_token(x_internal_token):
        raise HTTPException(401, "Unauthorized - Invalid token")
    
    # ì¤‘ë³µ ì²´í¬
    db = DBConnector()
    existing = db.get_file_by_id(request.data_id)
    
    if existing and existing.get('rag_index_status') == 'done':
        if not request.reindex_required_yn:
            return ConvertAndIndexResponse(
                status="already_done",
                job_id="",
                data_id=request.data_id,
                message="Already indexed"
            )
    
    job_id = str(uuid.uuid4())[:8]
    
    background_tasks.add_task(
        process_convert_and_index_prod,
        job_id=job_id,
        data_id=request.data_id,
        path=request.path,
        file_id=request.file_id,
        webhook_url=request.webhook_url,
        ocr_manual_required=request.ocr_manual_required,
        reindex_required_yn=request.reindex_required_yn
    )
    
    return ConvertAndIndexResponse(
        status="accepted",
        job_id=job_id,
        data_id=request.data_id,
        message="processing"
    )


@router.get("/status/{data_id}", response_model=StatusResponse)
def get_status(data_id: str, x_internal_token: Optional[str] = Header(None)):
    """ìƒíƒœ ì¡°íšŒ API (ìš´ì˜ìš©)"""
    if not verify_internal_token(x_internal_token):
        raise HTTPException(401, "Unauthorized - Invalid token")
    
    db = DBConnector()
    meta = db.get_file_by_id(data_id)
    
    if not meta:
        raise HTTPException(404, f"data_id {data_id} not found")
    
    return StatusResponse(
        data_id=data_id,
        rag_index_status=meta.get('rag_index_status', 'unknown'),
        parse_yn=meta.get('parse_yn'),
        chunk_count=meta.get('chunk_count'),
        parse_start_dt=str(meta.get('parse_start_dt')) if meta.get('parse_start_dt') else None,
        parse_end_dt=str(meta.get('parse_end_dt')) if meta.get('parse_end_dt') else None,
        milvus_doc_id=meta.get('milvus_doc_id')
    )


@router.get("/health")
def health_check():
    """í—¬ìŠ¤ ì²´í¬"""
    return {"status": "ok", "service": "java-router-production"}